import copy
import math

import numpy as np
import torch
from torch import nn
from torch.utils.data import DataLoader, Dataset
from scipy import linalg


def average_weights(local_weights):
    avg_weights = copy.deepcopy(local_weights[0])
    for key in avg_weights.keys():
        for i in range(1,len(local_weights)):
            avg_weights[key] += local_weights[i][key]
        avg_weights[key] = torch.div(avg_weights[key], len(local_weights))

    return avg_weights


def test_inference(args, model, test_dataset):

    model.eval()
    loss, total, correct = 0.0, 0.0 ,0.0

    device = 'cuda' if args.gpu else 'cpu'
    test_creterion = torch.nn.CrossEntropyLoss(reduction='sum')
    # criterion = nn.NLLLoss().to(device)
    criterion = test_creterion.to(device)
    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)

    for batch_idx, (images, labels) in enumerate(test_loader):
        images, labels = images.to(device), labels.to(device)

        outputs = model(images)
        batch_loss = criterion(outputs, labels)
        loss += batch_loss.item()

        _, pred_labels = torch.max(outputs, 1)
        pred_labels = pred_labels.view(-1)
        correct += torch.sum(torch.eq(pred_labels, labels)).item()
        total += len(labels)

    accuracy = correct / total
    return accuracy, loss
